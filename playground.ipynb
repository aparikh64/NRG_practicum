{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2241bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f609a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ecoshare_sales.xlsx', sheet_name='Data')\n",
    "#ca_tenure_bucket is blank, will delete\n",
    "df = df.drop('ca_tenure_bucket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27979fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engineer features based on order day\n",
    "df['order_day'] = pd.to_datetime(df['order_day'])\n",
    "df['order_day_month'] = df['order_day'].dt.strftime('%m')\n",
    "df['order_day_day_of_week'] = df['order_day'].dt.day_name()\n",
    "df['order_day_day_of_month'] = df['order_day'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29d84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94601, 36)\n",
      "Index(['order_day', 'accept', 'tos_flg', 'disconotice_flg',\n",
      "       'oam_activelogin_cnt', 'term_length', 'called_numcalls_cnt',\n",
      "       'latefee_flg', 'dwelling_type_cd', 'curr_usage', 'product_type_cd',\n",
      "       'pool', 'automatic_payment_flg', 'weblog_flg', 'risk_level',\n",
      "       'deposit_onhand_amt', 'ebill_enroll_flag', 'called_flg', 'oam_flg',\n",
      "       'sap_productname', 'numweblog_cnt', 'disconnects_flg', 'load_profile',\n",
      "       'city', 'zipcode', 'home_value', 'county', 'tdsp', 'dwelling_type',\n",
      "       'dma', 'ev_driver', 'segment', 'customer_id', 'order_day_month',\n",
      "       'order_day_day_of_week', 'order_day_day_of_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74564fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: \n",
      "NaN    84253\n",
      "Y      10348\n",
      "Name: tos_flg, dtype: int64\n",
      "after processing: \n",
      "blank    84253\n",
      "Y        10348\n",
      "Name: tos_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    90046\n",
      "Y     4555\n",
      "Name: disconotice_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "0    92515\n",
      "1     2086\n",
      "Name: oam_activelogin_cnt, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    85367\n",
      "Y     9234\n",
      "Name: latefee_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "S    55315\n",
      "M    39286\n",
      "Name: dwelling_type_cd, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "TERM    66041\n",
      "MTM     28560\n",
      "Name: product_type_cd, dtype: int64\n",
      "\n",
      "before processing: \n",
      "NaN    92642\n",
      "Y       1880\n",
      "N         79\n",
      "Name: pool, dtype: int64\n",
      "after processing: \n",
      "N    92721\n",
      "Y     1880\n",
      "Name: pool, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    74123\n",
      "Y    20478\n",
      "Name: automatic_payment_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    86205\n",
      "Y     8396\n",
      "Name: weblog_flg, dtype: int64\n",
      "\n",
      "before processing: \n",
      "L      44013\n",
      "NaN    35291\n",
      "M       9881\n",
      "H       5416\n",
      "Name: risk_level, dtype: int64\n",
      "after processing: \n",
      "L        44013\n",
      "blank    35291\n",
      "M         9881\n",
      "H         5416\n",
      "Name: risk_level, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    56441\n",
      "Y    38160\n",
      "Name: ebill_enroll_flag, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    74183\n",
      "Y    20418\n",
      "Name: called_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    51400\n",
      "Y    43201\n",
      "Name: oam_flg, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "\n",
      "no processing required: \n",
      "N    93902\n",
      "Y      699\n",
      "Name: disconnects_flg, dtype: int64\n",
      "\n",
      "before processing: \n",
      "R1      48637\n",
      "R2      44269\n",
      "R1PV      981\n",
      "R2PV      702\n",
      "NaN         6\n",
      "G1          4\n",
      "NL          1\n",
      "G3          1\n",
      "Name: load_profile, dtype: int64\n",
      "after processing: \n",
      "R1       48637\n",
      "R2       44269\n",
      "R1PV       981\n",
      "R2PV       702\n",
      "blank        6\n",
      "G1           4\n",
      "NL           1\n",
      "G3           1\n",
      "Name: load_profile, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "CNP    47430\n",
      "ONC    36515\n",
      "CPL     6893\n",
      "TNP     2398\n",
      "WTU     1365\n",
      "Name: tdsp, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "S    55575\n",
      "M    36957\n",
      "U     2069\n",
      "Name: dwelling_type, dtype: int64\n",
      "\n",
      "no processing required: \n",
      "N    93102\n",
      "Y     1499\n",
      "Name: ev_driver, dtype: int64\n",
      "\n",
      "before processing: \n",
      "4     18129\n",
      "3     15590\n",
      "6     10150\n",
      "11    10066\n",
      "1      7584\n",
      "5      6700\n",
      "8      6580\n",
      "12     4845\n",
      "10     4698\n",
      "9      4356\n",
      "7      2955\n",
      "2      2948\n",
      "Name: segment, dtype: int64\n",
      "after processing: \n",
      "Segment 4     18129\n",
      "Segment 3     15590\n",
      "Segment 6     10150\n",
      "Segment 11    10066\n",
      "Segment 1      7584\n",
      "Segment 5      6700\n",
      "Segment 8      6580\n",
      "Segment 12     4845\n",
      "Segment 10     4698\n",
      "Segment 9      4356\n",
      "Segment 7      2955\n",
      "Segment 2      2948\n",
      "Name: segment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#tos_flg\n",
    "print(\"before processing: \")\n",
    "print(df['tos_flg'].value_counts(dropna=False))\n",
    "df['tos_flg'].fillna('blank', inplace=True)\n",
    "print(\"after processing: \")\n",
    "print(df['tos_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#disconotice_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['disconotice_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#oam_activelogin_cnt no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['oam_activelogin_cnt'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#lots of unique values for term_length so exporting to a CSV and opening in MS Excel\n",
    "df['term_length'].value_counts(dropna=False).reset_index().rename(columns={\"index\": \"term_length\", \"term_length\": \"count\"}).to_csv('term_length.csv', index=False)\n",
    "#upon review, see 1 null record, 32 records with MM string, and 17 records with C& string\n",
    "#will fill null, and string records with imputed value (median)\n",
    "term_length_impute_list = df['term_length'].dropna().to_list()\n",
    "term_length_impute_list = [i for i in term_length_impute_list if (i != 'MM' and i != 'C&')]\n",
    "term_length_impute_list = list(map(int, term_length_impute_list))\n",
    "term_length_imputed_value = statistics.median(term_length_impute_list)\n",
    "df['term_length'] = df['term_length'].fillna(term_length_imputed_value)\n",
    "df['term_length'] = df['term_length'].replace(['MM', 'C&'], term_length_imputed_value)\n",
    "df['term_length'] = df['term_length'].astype(np.int64)\n",
    "\n",
    "#called_numcalls_cnt no need to preprocess, will evaluate test set if need to preprocess\n",
    "#df['called_numcalls_cnt'].value_counts(dropna=False)\n",
    "\n",
    "#latefee_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['latefee_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#dwelling_type_cd no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['dwelling_type_cd'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#lots of unique values for curr_usage so exporting to a CSV and opening in MS Excel\n",
    "df['curr_usage'].value_counts(dropna=False).reset_index().rename(columns={\"index\": \"curr_usage\", \"curr_usage\": \"count\"}).to_csv('curr_usage.csv', index=False)\n",
    "#upon review, see lot of null values so will fill null with imputed value (median)\n",
    "curr_usage_impute_list = df['curr_usage'].dropna().to_list()\n",
    "curr_usage_imputed_value = statistics.median(curr_usage_impute_list)\n",
    "df['curr_usage'] = df['curr_usage'].fillna(curr_usage_imputed_value)\n",
    "df['curr_usage'] = df['curr_usage'].astype(np.int64)\n",
    "\n",
    "#product_type_cd no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['product_type_cd'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#pool\n",
    "print(\"before processing: \")\n",
    "print(df['pool'].value_counts(dropna=False))\n",
    "df['pool'].fillna('N', inplace=True)\n",
    "print(\"after processing: \")\n",
    "print(df['pool'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#automatic_payment_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['automatic_payment_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#weblog_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['weblog_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#risk_level\n",
    "print(\"before processing: \")\n",
    "print(df['risk_level'].value_counts(dropna=False))\n",
    "df['risk_level'].fillna('blank', inplace=True)\n",
    "print(\"after processing: \")\n",
    "print(df['risk_level'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#lots of unique values for deposit_onhand_amt so exporting to a CSV and opening in MS Excel\n",
    "df['deposit_onhand_amt'].value_counts(dropna=False).reset_index().rename(columns={\"index\": \"deposit_onhand_amt\", \"deposit_onhand_amt\": \"count\"}).to_csv('deposit_onhand_amt.csv', index=False)\n",
    "#saw lot of blank values but no 0, so assuming blanks mean 0 for now\n",
    "df['deposit_onhand_amt'] = df['deposit_onhand_amt'].fillna(0)\n",
    "\n",
    "#ebill_enroll_flag no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['ebill_enroll_flag'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#called_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['called_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#oam_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['oam_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#lots of unique values for sap_productname so exporting to a CSV and opening in MS Excel\n",
    "df['sap_productname'].value_counts(dropna=False).reset_index().rename(columns={\"index\": \"sap_productname\", \"sap_productname\": \"count\"}).to_csv('sap_productname.csv', index=False)\n",
    "#noticed some blank values so will fill those in as their own category\n",
    "df['sap_productname'] = df['sap_productname'].fillna('blank')\n",
    "\n",
    "#numweblog_cnt no need to preprocess, will evaluate test set if need to preprocess\n",
    "#print(\"no processing required: \")\n",
    "#print(df['numweblog_cnt'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#disconnects_flg no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['disconnects_flg'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#load_profile\n",
    "print(\"before processing: \")\n",
    "print(df['load_profile'].value_counts(dropna=False))\n",
    "df['load_profile'].fillna('blank', inplace=True)\n",
    "print(\"after processing: \")\n",
    "print(df['load_profile'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#location fields - fill in any nulls with their own category\n",
    "df['city'] = df['city'].fillna('blank')\n",
    "df['county'] = df['county'].fillna('blank')\n",
    "df['dma'] = df['dma'].fillna('blank')\n",
    "\n",
    "#home value\n",
    "#lots of unique values for home_value so exporting to a CSV and opening in MS Excel\n",
    "df['home_value'].value_counts(dropna=False).reset_index().rename(columns={\"index\": \"home_value\", \"home_value\": \"count\"}).to_csv('home_value.csv', index=False)\n",
    "#upon review, lot of null values, so we will impute with median\n",
    "df['home_value'] = df['home_value'].fillna(df['home_value'].median())\n",
    "\n",
    "#tdsp no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['tdsp'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#dwelling_type no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['dwelling_type'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#ev_driver no need to preprocess, will evaluate test set if need to preprocess\n",
    "print(\"no processing required: \")\n",
    "print(df['ev_driver'].value_counts(dropna=False))\n",
    "print()\n",
    "\n",
    "#segment, need to convert from numerical to categorical\n",
    "print('before processing: ')\n",
    "print(df['segment'].value_counts(dropna=False))\n",
    "print('after processing: ')\n",
    "df['segment'] = 'Segment ' + df['segment'].astype(str)\n",
    "print(df['segment'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81fd1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible feature generation:\n",
    "# turn order day into month\n",
    "# turn order day into day of week\n",
    "# turn order day into days from end of the month (approaching month end)\n",
    "# use customer ID to figure out how many times you're calling the same customer\n",
    "# sap_productname consolidated to a few different plan type dummy indicators\n",
    "# create model to predict missing variables, such as sap_productname\n",
    "# need to figure out what to do with zip code\n",
    "# data cleaning with low home values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776deaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions:\n",
    "# for term length, what is C& and MM? for now, deleting those values and imputing\n",
    "# if curr usage is blank, is it missing or indicating 0 usage?\n",
    "# if pool is blank, is it indicating they don't have a pool or you don't know?\n",
    "# if deposit amount on hand is blank, is it 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6a91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5506e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
